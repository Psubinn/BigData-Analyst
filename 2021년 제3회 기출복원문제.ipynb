{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076f87dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yemoonsaBigdata' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/AnalyticsKnight/yemoonsaBigdata/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0355f",
   "metadata": {},
   "source": [
    "작업형 제 1유형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5f109",
   "metadata": {},
   "source": [
    "(1) 다음은 California Housing 데이터 세트이다. 데이터 중 결측치가 있는 경우 해당 데이터의 행을 모두 제거하고, 첫 번째 행부터 순서대로 70%까지의 데이터를 훈련 데이터로 추출한 데이터 세트를 구성한다. 변수 중 'housing_median_age'의 Q1(제1사분위수) 값을 정수로 계산하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8297c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "housing = pd.read_csv('./yemoonsaBigdata/datasets/Part3/301_housing.csv')\n",
    "print(housing.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8018f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터 : 20640\n",
      "결측값 제거 데이터 : 20433\n"
     ]
    }
   ],
   "source": [
    "housing_dropna = housing.dropna(inplace=False)\n",
    "print('원본 데이터 :',len(housing))\n",
    "print('결측값 제거 데이터 :', len(housing_dropna))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c52247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70% 데이터 추출 :  14303\n"
     ]
    }
   ],
   "source": [
    "housing_dropna_70 = housing_dropna.iloc[: int(len(housing_dropna) * 0.7)]\n",
    "print(\"70% 데이터 추출 : \", len(housing_dropna_70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0da142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "result = int( housing_dropna_70['housing_median_age'].quantile([0.25]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd856b",
   "metadata": {},
   "source": [
    "(2) 다음은 국가별 연도별 인구 10만 명당 결핵 유병률 데이터 세트이다. 2000년도의 국가별 결핵 유병률 데이터 세트에서 2000년도의 평균값보다 더 큰 유병률 값을 가진 국가의 수를 계산하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e586fff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  Afghanistan  Albania  Algeria  Andorra  Angola  Antigua & Barbuda  \\\n",
      "0  1999            0     89.0     25.0    245.0   217.0              102.0   \n",
      "1  2000            0    132.0      0.0    138.0    57.0              128.0   \n",
      "2  2001            0     54.0     14.0    312.0    45.0               45.0   \n",
      "3  2002            0      4.9      0.7     12.4     5.9                4.9   \n",
      "\n",
      "   Argentina  Armenia  Australia  ...  Tanzania    USA  Uruguay  Uzbekistan  \\\n",
      "0      193.0     21.0      261.0  ...      36.0  249.0    115.0        25.0   \n",
      "1       25.0    179.0       72.0  ...       6.0  158.0     35.0       101.0   \n",
      "2      221.0     11.0      212.0  ...       1.0   84.0    220.0         8.0   \n",
      "3        8.3      3.8       10.4  ...       5.7    8.7      6.6         2.4   \n",
      "\n",
      "   Vanuatu  Venezuela  Vietnam  Yemen  Zambia  Zimbabwe  \n",
      "0     21.0      333.0      111    6.0    32.0      64.0  \n",
      "1     18.0      100.0        2    0.0    19.0      18.0  \n",
      "2     11.0        3.0        1    0.0     4.0       4.0  \n",
      "3      0.9        7.7        2    0.1     2.5       4.7  \n",
      "\n",
      "[4 rows x 194 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "disease = pd.read_csv('./yemoonsaBigdata/datasets/Part3/302_worlddata.csv')\n",
    "print(disease.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fccc2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  Afghanistan  Albania  Algeria  Andorra  Angola  Antigua & Barbuda  \\\n",
      "1  2000            0    132.0      0.0    138.0    57.0              128.0   \n",
      "\n",
      "   Argentina  Armenia  Australia  ...  Tanzania    USA  Uruguay  Uzbekistan  \\\n",
      "1       25.0    179.0       72.0  ...       6.0  158.0     35.0       101.0   \n",
      "\n",
      "   Vanuatu  Venezuela  Vietnam  Yemen  Zambia  Zimbabwe  \n",
      "1     18.0      100.0        2    0.0    19.0      18.0  \n",
      "\n",
      "[1 rows x 194 columns]\n"
     ]
    }
   ],
   "source": [
    "disease_2000 = disease[disease['year'] == 2000]\n",
    "print(disease_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abc2ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             value\n",
      "Afghanistan    0.0\n",
      "Albania      132.0\n",
      "Algeria        0.0\n",
      "Andorra      138.0\n",
      "Angola        57.0\n",
      "...            ...\n",
      "Venezuela    100.0\n",
      "Vietnam        2.0\n",
      "Yemen          0.0\n",
      "Zambia        19.0\n",
      "Zimbabwe      18.0\n",
      "\n",
      "[193 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "disease_2000_T = disease_2000.T\n",
    "disease_2000_T_drop = disease_2000_T.drop(['year'], axis=0)\n",
    "disease_2000_T_drop.columns=['value']\n",
    "\n",
    "print(disease_2000_T_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac1ae5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.01036269430051\n"
     ]
    }
   ],
   "source": [
    "mean = disease_2000_T_drop['value'].mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "778578d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      value\n",
      "Albania               132.0\n",
      "Andorra               138.0\n",
      "Antigua & Barbuda     128.0\n",
      "Armenia               179.0\n",
      "Bahamas               176.0\n",
      "...                     ...\n",
      "United Arab Emirates  135.0\n",
      "United Kingdom        126.0\n",
      "USA                   158.0\n",
      "Uzbekistan            101.0\n",
      "Venezuela             100.0\n",
      "\n",
      "[76 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "disease_final = disease_2000_T_drop[disease_2000_T_drop['value']  > mean]\n",
    "print(disease_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7297106",
   "metadata": {},
   "source": [
    "(3) 다음은 Titanic 데이터 세트이다. 주어진 데이터 세트의 컬럼 중 빈 값 또는 결측치를 확인하여, 결측치의 비율이 가장 높은 변수명을 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e204ce55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        773 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv('./yemoonsaBigdata/datasets/Part3/303_titanic.csv')\n",
    "print(titanic.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b0b042c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          118\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic_isna = titanic.isna().sum()\n",
    "print(titanic_isna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d45e0ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "max_ind = titanic_isna.argmax()\n",
    "print(max_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91e57323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n"
     ]
    }
   ],
   "source": [
    "result = titanic_isna.index[max_ind]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc96a5",
   "metadata": {},
   "source": [
    "3. 작업형 제2유형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd61aaa",
   "metadata": {},
   "source": [
    "다음은 Travel Insurance 데이터 세트이다. 주어진 훈련 데이터 세트를 이용하여 고객별 여행보험 가입 여부 예측 모형을 만들고, 가장 높은 Accuracy 값을 가지는 최종 모델을 도출하시오. 해당 모델을 활용하여 보험 가입 여부 예측값을 계산하고 결괏값은 csv 파일로 제출하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0caeb83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Age               Employment Type GraduateOrNot  AnnualIncome  \\\n",
      "0  1704   26  Private Sector/Self Employed           Yes       1400000   \n",
      "1   491   28  Private Sector/Self Employed           Yes       1100000   \n",
      "2   414   33  Private Sector/Self Employed           Yes       1400000   \n",
      "3   120   28  Private Sector/Self Employed           Yes        800000   \n",
      "4  1268   33             Government Sector           Yes       1000000   \n",
      "\n",
      "   FamilyMembers  ChronicDiseases FrequentFlyer EverTravelledAbroad  \\\n",
      "0              3                1            No                 Yes   \n",
      "1              4                1            No                  No   \n",
      "2              4                0            No                 Yes   \n",
      "3              3                1            No                  No   \n",
      "4              5                0            No                 Yes   \n",
      "\n",
      "   TravelInsurance  \n",
      "0                0  \n",
      "1                1  \n",
      "2                1  \n",
      "3                0  \n",
      "4                1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('./yemoonsaBigdata/datasets/Part3/304_travel_Insurance_train.csv')\n",
    "df_test = pd.read_csv('./yemoonsaBigdata/datasets/Part3/304_travel_Insurance_test.csv')\n",
    "print(df_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8fae092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 9) (497, 9) (1490, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train.drop(columns='TravelInsurance')\n",
    "y_train = df_train[['ID', 'TravelInsurance']]\n",
    "\n",
    "x_test = df_test.copy()\n",
    "\n",
    "x_train.to_csv('./yemoonsaBigdata/datasets/Part3/304_x_train.csv', index=False)\n",
    "x_test.to_csv('./yemoonsaBigdata/datasets/Part3/304_x_test.csv', index=False)\n",
    "y_train.to_csv('./yemoonsaBigdata/datasets/Part3/304_y_train.csv', index=False)\n",
    "\n",
    "x_train = pd.read_csv('./yemoonsaBigdata/datasets/Part3/304_x_train.csv')\n",
    "x_test = pd.read_csv('./yemoonsaBigdata/datasets/Part3/304_x_test.csv')\n",
    "y_train = pd.read_csv('./yemoonsaBigdata/datasets/Part3/304_y_train.csv')\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c2d719d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1987 entries, 0 to 496\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID                   1987 non-null   int64 \n",
      " 1   Age                  1987 non-null   int64 \n",
      " 2   Employment Type      1987 non-null   object\n",
      " 3   GraduateOrNot        1987 non-null   object\n",
      " 4   AnnualIncome         1987 non-null   int64 \n",
      " 5   FamilyMembers        1987 non-null   int64 \n",
      " 6   ChronicDiseases      1987 non-null   int64 \n",
      " 7   FrequentFlyer        1987 non-null   object\n",
      " 8   EverTravelledAbroad  1987 non-null   object\n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 155.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_x = pd.concat([x_train, x_test])\n",
    "print(df_x.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f187c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private Sector/Self Employed    1417\n",
      "Government Sector                570\n",
      "Name: Employment Type, dtype: int64 \n",
      "\n",
      "Yes    1692\n",
      "No      295\n",
      "Name: GraduateOrNot, dtype: int64 \n",
      "\n",
      "No     1570\n",
      "Yes     417\n",
      "Name: FrequentFlyer, dtype: int64 \n",
      "\n",
      "No     1607\n",
      "Yes     380\n",
      "Name: EverTravelledAbroad, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "obj_cols = ['Employment Type', 'GraduateOrNot','FrequentFlyer','EverTravelledAbroad']\n",
    "\n",
    "for i in obj_cols:\n",
    "    print(df_x[i].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4639ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    950\n",
      "1    540\n",
      "Name: TravelInsurance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train['TravelInsurance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fcee060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1987 entries, 0 to 496\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   ID                   1987 non-null   int64\n",
      " 1   Age                  1987 non-null   int64\n",
      " 2   Employment Type      1987 non-null   int64\n",
      " 3   GraduateOrNot        1987 non-null   int64\n",
      " 4   AnnualIncome         1987 non-null   int64\n",
      " 5   FamilyMembers        1987 non-null   int64\n",
      " 6   ChronicDiseases      1987 non-null   int64\n",
      " 7   FrequentFlyer        1987 non-null   int64\n",
      " 8   EverTravelledAbroad  1987 non-null   int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 155.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_le = df_x.copy()\n",
    "df_le['Employment Type'] = df_x['Employment Type'].replace(['Private Sector/Self Employed',\n",
    "                                                            'Government Sector'], [0,1])\n",
    "df_le['GraduateOrNot'] = df_x['GraduateOrNot'].replace(['No','Yes'],[0,1])\n",
    "df_le['FrequentFlyer'] = df_x['FrequentFlyer'].replace(['No','Yes'],[0,1])\n",
    "df_le['EverTravelledAbroad'] = df_x['EverTravelledAbroad'].replace(['No','Yes'],[0,1])\n",
    "\n",
    "print(df_le.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37e0e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def get_scores(model, xtrain, xtest, ytrain, ytest):\n",
    "    A = model.score(xtrain, ytrain)\n",
    "    ypred = model.predict_proba(xtest)[:,1]\n",
    "    B = roc_auc_score(ytest,ypred)\n",
    "    return '{:.4f} {:.4f}'.format(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12787373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def make_models(xtrain, xtest, ytrain, ytest):\n",
    "    model1 = LogisticRegression().fit(xtrain, ytrain)\n",
    "    print('model1', get_scores(model1, xtrain, xtest, ytrain, ytest))\n",
    "\n",
    "    model2 = DecisionTreeClassifier(random_state=0).fit(xtrain, ytrain)\n",
    "    print('model2', get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
    "\n",
    "    for d in range(3, 8):\n",
    "        model2 = DecisionTreeClassifier(max_depth=d, random_state=0).fit(xtrain, ytrain)\n",
    "        print('model2', d, get_scores(model2, xtrain, xtest, ytrain, ytest))\n",
    "\n",
    "    model3 = RandomForestClassifier(random_state=0).fit(xtrain, ytrain)\n",
    "    print('model3', get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
    "\n",
    "    for d in range(3, 8):\n",
    "        model3 = RandomForestClassifier(500, max_depth=d, random_state=0).fit(xtrain, ytrain)\n",
    "        print('model3', d, get_scores(model3, xtrain, xtest, ytrain, ytest))\n",
    "\n",
    "    model4 = XGBClassifier(eval_metric='logloss', use_label_encoder=False).fit(xtrain, ytrain)\n",
    "    print('model4', get_scores(model4, xtrain, xtest, ytrain, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "328bd04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'pandas.core.series.Series'>\n",
      "(1490, 8) (497, 8) (1490,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_le = df_le.drop(columns=['ID'])\n",
    "\n",
    "x_le_train = x_le[:1490]\n",
    "x_le_test = x_le[1490:]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_le_train)\n",
    "x_fin_train = scaler.transform(x_le_train)\n",
    "x_fin_test = scaler.transform(x_le_test)\n",
    "\n",
    "y_fin_train = y_train['TravelInsurance']\n",
    "\n",
    "print(type(x_fin_train), type(x_fin_test), type(y_fin_train))\n",
    "print(x_fin_train.shape, x_fin_test.shape, y_fin_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6d1f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1117, 8) (373, 8) (1117,) (373,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_fin_train, y_fin_train, test_size=0.25, \n",
    "                                                stratify = y_fin_train)\n",
    "\n",
    "print(xtrain.shape, xtest.shape, ytrain.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c885a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 0.7708 0.7789\n",
      "model2 0.9409 0.7876\n",
      "model2 3 0.8397 0.8074\n",
      "model2 4 0.8397 0.8204\n",
      "model2 5 0.8451 0.8209\n",
      "model2 6 0.8505 0.8239\n",
      "model2 7 0.8523 0.8419\n",
      "model3 0.9409 0.8182\n",
      "model3 3 0.7959 0.8112\n",
      "model3 4 0.8236 0.8075\n",
      "model3 5 0.8424 0.8033\n",
      "model3 6 0.8478 0.8094\n",
      "model3 7 0.8505 0.8177\n",
      "model4 0.9167 0.8205\n"
     ]
    }
   ],
   "source": [
    "make_models(xtrain,xtest,ytrain,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c757ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_model 0.8397 0.8204\n"
     ]
    }
   ],
   "source": [
    "final_model = DecisionTreeClassifier(max_depth=4).fit(xtrain,ytrain)\n",
    "print('final_model', get_scores(final_model, xtrain,xtest,ytrain,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89fbf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict_proba(x_fin_test)[:,1]\n",
    "\n",
    "result = pd.DataFrame({'y_pred' : y_pred})\n",
    "result.to_csv('./yemoonsaBigdata/res/Insurance_y_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a8a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
